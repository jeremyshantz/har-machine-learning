```{r, echo=FALSE}
suppressPackageStartupMessages(library('knitr')) 
suppressPackageStartupMessages(library(caret))
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(randomForest))
set.seed(222)
options(width = 100)
```
---
title: "Machine Learning Prediction of Execution Quality in Weight Lifting Exercises"
author: "Jeremy Shantz"
date: '2015-02-22'
output: html_document
---

In this study we use machine learning to predict the execution quality of test subjects performing [unilateral dumbbell biceps curl](https://www.youtube.com/results?search_query=Unilateral+Dumbbell+Biceps+Curl) using data [[1]](#Velloso) from sensors worn by the subjects. From the data's 160 variables we select 52 features and apply a random forest algorithm to construct a statistical model. We apply that model to a test data set to predict whether each observation corresponds to the correct execution of the exercise or to one of five ways it can be executed incorrectly.

More information about the data is available: [Weight Lifting Exercises Dataset](http://groupware.les.inf.puc-rio.br/har#weight_lifting_exercises).

## Building the model

### Training and Test Sets
Load the raw training and testing data sets.
```{r, cache=TRUE, echo=TRUE}
rawData <- read.csv('./data/pml-training.csv')
finalTestData <- read.csv('./data/pml-testing.csv')
```

Partition the training data into training and testing data sets. Sixty percent 
of the data is used to train our model, reserving 40% of the data to test 
against so we can measure the effectiveness of our model.

```{r, cache=TRUE, echo=TRUE}
indexes <- createDataPartition(y=rawData$classe, p=0.60, list=FALSE)
train.original <- rawData[indexes,]
test <- rawData[-indexes,]
```

Random sample from the data:
```{r, cache=TRUE, echo=TRUE}
head(train.original[, sample(names(train.original), 28)],1)
```

### Feature Selection
With 160 potential features, our first task is to remove low-value data. We
start by removing the first 7 columns which are clearly not predictors.

```{r, cache=TRUE, echo=TRUE}
train <- train.original[, -7:-1]
```

Next we remove columns with little variation since they will not be useful in
explaining the variation we observe in the `classe` variable.

```{r, cache=TRUE, echo=TRUE}
nzvar <- nearZeroVar(train, saveMetrics=TRUE)
train <- train[, !(nzvar$nzv)]
```

There remain many columns which primarily contain the NA value. Calculate the 
count of NAs in each column.

```{r, cache=TRUE, echo=TRUE}
sapply(1:ncol(train) - 1, function(i) { sum(is.na(train[,i]))  })
```

Remove all columns where the count of NA is non-zero.

```{r, cache=TRUE, echo=TRUE}
indexes <- sapply(1:ncol(train), function(i) { ifelse(sum(is.na(train[,i])) > 0, -i, i)  })
train <- train[, indexes[indexes < 0]]
```

### Random Forest

With a set of 52 predictors, we train a model using a random forest. Our outcome variable is `classe` (containing five possible values A, B, C, D, E) and the model is trained against the `r nrow(train) ` observations in the training data set.
```{r, cache=TRUE, echo=TRUE}
model <- train(classe ~., data=train, method="rf", tuneGrid=data.frame(mtry=2) )
```

When applied to the training data set, the model's accuracy is 99.8%.

```{r, cache=TRUE, echo=TRUE}
predictions <- predict(model, train)
mt <- confusionMatrix(predictions, train$classe)
mt$overall[1:5]
```

## Cross validation

The random forest algorithm internally uses a bootstrapped resampling strategy for cross validation. In this case, it made 25 repetitions using the 'boot' method.

```{r, cache=TRUE, echo=TRUE}
model$control$method
model$control$repeats
```

### Out of Sample Error Rate - Random Forest Bootstrap Resampling

The model predicts an out of sample error rate of 0.9%.

```{r, cache=TRUE, echo=TRUE}
model$finalModel
```
 
### Out of Sample Error Rate - Applying the Model to the Test Data

We can now apply the prediction algorithm to the test set we created for this purpose. Because it was not used to train the model, the test set is an unbiased measure of the out of sample error rate.

```{r, cache=TRUE, echo=TRUE}
testResults <- confusionMatrix(predict(model, test), test$classe)
testResults$overall[1:6]
testResults$table
errorRate <- round(1 - testResults$overall[[1]], 4)
paste('The error rate is', errorRate, '%')
```

## Test Cases 
We also applied this machine learning algorithm to 20 reserved test cases where the 
`classe` value was not immediately available. The model was able predict `classe` with 100% accuracy. 

```{r}
answers <- as.character(predict(model, finalTestData))
```

## Citations
<div id="Velloso"></div>
Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. [Qualitative Activity Recognition of Weight Lifting Exercises](http://groupware.les.inf.puc-rio.br/work.jsf?p1=11201). Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013. 

<!-- Add extra space below to make the citation link more obvious -->
<div style="height:300px;"></div>
